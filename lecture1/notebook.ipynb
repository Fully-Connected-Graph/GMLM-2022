{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Student Performance Prediction\n",
        "\n",
        "Welcome to the practice session of Lecture 1. During this tutorial, we will use a dataset acquired from [Kaggle](https://www.kaggle.com/datasets/larsen0966/student-performance-data-set) to illustrate the implementation of an ML model. In this dataset, the information regarding students in two Portuguese schools is mentioned. Using the given data, we desire to predict the final grade of student (G3).\n",
        "\n",
        "Description of the dataset:\n",
        "- `school`: student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)\n",
        "- `sex`: student's sex (binary: 'F' - female or 'M' - male)\n",
        "- `age`: student's age (numeric: from 15 to 22)\n",
        "- `address`: student's home address type (binary: 'U' - urban or 'R' - rural)\n",
        "- `famsize`: family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n",
        "- `Pstatus`: parent's cohabitation status (binary: 'T' - living together or 'A' - apart)\n",
        "- `Medu`: mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 is 5th to 9th grade, 3 is secondary education or 4 is higher education)\n",
        "- `Fedu`: fathers's education (numeric: 0 - none, 1 - primary education (4th grade), 2 is 5th to 9th grade, 3 is secondary education or 4 is higher education)\n",
        "- `Mjob`: mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
        "- `Fjob`: father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n",
        "- `reason`: reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n",
        "- `guardian`: student's guardian (nominal: 'mother', 'father' or 'other')\n",
        "- `traveltime`: home to school travel time (numeric: 1 is < 15 min., 2 is 15 to 30 min., 3 is 30 min. to 1 hour, or 4 is > 1 hour)\n",
        "- `studytime`: weekly study time (numeric: 1 is < 2 hours, 2 is 2 to 5 hours, 3 is 5 to 10 hours, or 4 is >10 hours)\n",
        "- `failures`: number of past class failures (numeric: n if 1 ≤ n < 3, else 4)\n",
        "- `schoolsup`: extra educational support (binary: yes or no)\n",
        "- `famsup`: family educational support (binary: yes or no)\n",
        "- `paid`: extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
        "- `activities`: extra-curricular activities (binary: yes or no)\n",
        "- `nursery`: attended nursery school (binary: yes or no)\n",
        "- `higher`: wants to take higher education (binary: yes or no)\n",
        "- `internet`: Internet access at home (binary: yes or no)\n",
        "- `famrel`: quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
        "- `freetime`: free time after school (numeric: from 1 - very low to 5 - very high)\n",
        "- `goout`: going out with friends (numeric: from 1 - very low to 5 - very high)\n",
        "- `Dalc`: workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
        "- `Walc`: weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
        "- `health`: current health status (numeric: from 1 - very bad to 5 - very good)\n",
        "- `absences`: number of school absences (numeric: from 0 to 93)\n",
        "- `G1`: first period grade (numeric: from 0 to 20)\n",
        "- `G2`: second period grade (numeric: from 0 to 20)\n",
        "- `G3`: final period grade (numeric: from 0 to 20)\n",
        "\n",
        "First, we need to download the dataset to the Colab instance"
      ],
      "metadata": {
        "id": "szDjhqcs1P3U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSCNpLKFxMj1"
      },
      "outputs": [],
      "source": [
        "# download the dataset\n",
        "!wget https://fully-connected-graph.github.io/datasets/student-performance/dataset.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are running this code on your local machine uncomment and run this cell to install the necessary libraries."
      ],
      "metadata": {
        "id": "ZYP8sUmqRDQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install numpy pandas sklearn lightgbm"
      ],
      "metadata": {
        "id": "9TqAidBQQ0eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify that data has been downloaded, we can press the folder icon on the left panel to view the directory of the instance.\n",
        "\n",
        "Now that we have our dataset, we can start working with python to create our model. Let's import all the necessary functions and libraries."
      ],
      "metadata": {
        "id": "GCujFps71iub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.dummy import DummyRegressor"
      ],
      "metadata": {
        "id": "qfl_RKfIxPPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving and using the random state allows you to reproduce the results later."
      ],
      "metadata": {
        "id": "I49d6Kz7RaLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE=17112022"
      ],
      "metadata": {
        "id": "plxmVAUCRr3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After executing the above block we can load the dataset and see it"
      ],
      "metadata": {
        "id": "IkUoUPAP3vUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"dataset.csv\")\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "jfJbDXt73ytw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "Data acquired in the real world is often messy and incomplete. Before we create our model, it is a good idea to check if any column is missing data. Thankfully, pandas comes to our rescue and allows us to see a summary of the dataset."
      ],
      "metadata": {
        "id": "xCPjBUhH3m8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "-fX7rw6uxPSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 649 non-null out of 649 in each column, this means that no data is missing. Awesome! "
      ],
      "metadata": {
        "id": "fHkPFcVz4JMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing\n",
        "\n",
        "Let's prepare the dataset for training the machine learning models. As we saw prevously:\n",
        "- We don't have to deal with omissions (The data is complete)\n",
        "- Some data is categorical, and we will have to one hot encode it\n",
        "- We have to split the data into train, validation and test sets\n",
        "\n",
        "Let's begin by one hot encoding the categorical data. We first need to specify the categorical features.\n",
        "\n",
        "<details>\n",
        "<summary style=\"font-size:1.5rem\"> Hint\n",
        "</summary>\n",
        "\n",
        "Look at the description of the data at the top and infer what data is categorical.\n",
        "\n",
        "<details>\n",
        "<summary style=\"font-size:1.5rem\"> Answer\n",
        "</summary>\n",
        "\n",
        "<pre>\n",
        "categorical_feat = [\n",
        "    \"school\",\n",
        "    \"sex\",\n",
        "    \"address\",\n",
        "    \"famsize\",\n",
        "    \"Pstatus\",\n",
        "    \"Mjob\",\n",
        "    \"Fjob\",\n",
        "    \"reason\",\n",
        "    \"guardian\",\n",
        "    \"schoolsup\",\n",
        "    \"famsup\",\n",
        "    \"paid\",\n",
        "    \"activities\",\n",
        "    \"nursery\",\n",
        "    \"higher\",\n",
        "    \"internet\",\n",
        "    \"romantic\"\n",
        "]\n",
        "</pre>\n",
        "\n",
        "</details>\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "ZOKgCI2Y4xd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Task 1. identify what features are categorical, list there names as strings below\n",
        "\"\"\"\"\n",
        "\n",
        "categorical_feat = [\n",
        "  # write your code here\n",
        "]"
      ],
      "metadata": {
        "id": "r8ahZpXut0pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we know the categorical features, we need to isolate them from the rest of the dataset and one hot encode them. In pandas, one way to do it is by calling [`pd.get_dummies`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) method.\n",
        "\n",
        "<details>\n",
        "<summary style=\"font-size:1.5rem\"> Hint\n",
        "</summary>\n",
        "\n",
        "To subindex the data use `data[categorical_feat]`. \n",
        "\n",
        "To also account for redundancy set the `drop_first` attribute to  to true. That way you will have one less column for each feature. Having all of them zero implies that the dropped one is true.\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary style=\"font-size:1.5rem\"> Hint 2\n",
        "</summary>\n",
        "\n",
        "<pre>\n",
        "ohe_data = pd.get_dummies(\n",
        "    data[categorical_feat],\n",
        "    drop_first=True\n",
        ")\n",
        "</pre>\n",
        "\n",
        "</details>\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "MgO7qytN3mE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encode the data (or how it's otherwise called dummy)\n",
        "\n",
        "\"\"\"\n",
        "Task 2. One hot encode the categorical features. To select them you can subindex them from data variable.\n",
        "See the documentation on how to pass the data to it. \n",
        "\"\"\"\n",
        "\n",
        "ohe_data = pd.get_dummies(\n",
        "    # write code here\n",
        ")\n",
        "\n",
        "ohe_data.head()"
      ],
      "metadata": {
        "id": "DJt-jtY84zk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can work towards recombining the dataset since the categorical data is in a workable form. We already have the categorical data isolated so we need to do the same for the numerical data. We'll use the [`df.drop`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) method for that.\n",
        "\n",
        "<details>\n",
        "<summary style=\"font-size:1.5rem\"> Hint\n",
        "</summary>\n",
        "\n",
        "Just put the names of the columns that are categorical. The left values will be numerical.\n",
        "\n",
        "<details>\n",
        "<summary style=\"font-size:1.5rem\"> Hint 2\n",
        "</summary>\n",
        "\n",
        "<pre>\n",
        "num_data = data.drop(categorical_feat, axis=1)\n",
        "</pre>\n",
        "\n",
        "</details>\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "3tKWkeWP3ytn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the numerical feautures\n",
        "\n",
        "\"\"\"\n",
        "Task 3. Separate the numerical data from categorical\n",
        "\"\"\"\n",
        "\n",
        "num_data = data.drop(\n",
        "    # write code here, \n",
        "    axis=1\n",
        ")\n",
        "\n",
        "num_data.head()"
      ],
      "metadata": {
        "id": "tIfNZrbv7NME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we concatenate the OHE and numerical features back together."
      ],
      "metadata": {
        "id": "s8IIV7_IyFpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prep_data = pd.concat([\n",
        "    ohe_data,\n",
        "    num_data\n",
        "], axis=1)\n",
        "\n",
        "prep_data.head()"
      ],
      "metadata": {
        "id": "3IFaYApE60U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataset can now be used for machine learning. We can proceed to the next step of pre-processing which is to split the dataset into a training and testing component.\n",
        "\n",
        "First, we need to split the pre-processed data into features and target feature.\n",
        "\n",
        "<details>\n",
        "<summary>Hint</summary>\n",
        "<pre>\n",
        "features = prep_data.drop(\n",
        "    \"G3\", \n",
        "    axis=1\n",
        ")\n",
        "target = prep_data[\"G3\"]\n",
        "</pre>\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "QrtiwUZmyOvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Task 4. Separate the target feature (G3) from rest of the data\n",
        "\"\"\"\n",
        "\n",
        "features = prep_data.drop(\n",
        "    # your code here, \n",
        "    axis=1\n",
        ")\n",
        "target = prep_data[\n",
        "    # your code here\n",
        "]"
      ],
      "metadata": {
        "id": "eTYiEulV7Ydk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's split the data into train and test sets, in a 80:20 ratio"
      ],
      "metadata": {
        "id": "Jutcv2G2x4dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_train, features_test, target_train, target_test = train_test_split(\n",
        "    features,\n",
        "    target,\n",
        "    test_size = .2,\n",
        "    random_state=RANDOM_STATE\n",
        ")"
      ],
      "metadata": {
        "id": "zCdPsoMV8Vs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To determine how the splitting took place, we can look at the shape of the features to get their dimensions."
      ],
      "metadata": {
        "id": "FzuCQzX_41QC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(features_train.shape)\n",
        "print(features_test.shape)"
      ],
      "metadata": {
        "id": "Qa4iz3Kw9P4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 519 items in the train set and 130 in test.\n",
        "\n",
        "With this step, we are done with pre-processing and can now work on training the model. "
      ],
      "metadata": {
        "id": "5gJUkPAR9oCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training\n",
        "\n",
        "We will train 4 models on the train set and select the best based on the validation set. In the next section, we will test the best model on the test set.\n",
        "\n",
        "The four models we will examine are:\n",
        "- Decision trees\n",
        "- Random forest \n",
        "- Linear regression\n",
        "- Gradient boosting\n",
        "\n",
        "To make comparison between the models easier, we will create a dataframe to store the performance of each model."
      ],
      "metadata": {
        "id": "FKKiLK3j-B-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# custom function to display the model results\n",
        "\n",
        "results = pd.DataFrame([], columns=['Model', 'Best parameters', 'MSE'])\n",
        "results.set_index('Model', inplace=True)\n",
        "\n",
        "def add_result(model_name, best_params, neg_result):\n",
        "    results.loc[model_name] = [best_params, -neg_result]\n",
        "    display(results.loc[[model_name]])\n",
        "\n",
        "results.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "edExRMeaohFm",
        "outputId": "3cde4e33-eae9-4d28-add2-12c79852aa1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Best parameters, MSE]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1f5d795-55a6-40b5-b1cb-524221c314e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Best parameters</th>\n",
              "      <th>MSE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1f5d795-55a6-40b5-b1cb-524221c314e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1f5d795-55a6-40b5-b1cb-524221c314e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1f5d795-55a6-40b5-b1cb-524221c314e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression\n",
        "\n",
        "Linear regression models are different from the other models. We do not need to pass in any parameters for the model to work. So, we will just use cross validation to get its preformace."
      ],
      "metadata": {
        "id": "2IjF_1v-rUrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LinearRegression()\n",
        "\n",
        "lr_score = cross_val_score(\n",
        "    lr_model,\n",
        "    features_train,\n",
        "    target_train,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ").mean()\n",
        "\n",
        "add_result(\"Linear Regression\", {}, lr_score)"
      ],
      "metadata": {
        "id": "FNWdjIZRFjey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tree based models require parameters in order to be trained on data. If not specified they use the default values. But, we can search for the best parameters using [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). \n",
        "\n",
        "The best parameters for a model are unique to each dataset. Grid search is passed a list of different parameters and checks the model on all combinations to obtain the best params."
      ],
      "metadata": {
        "id": "SQlHN4kC7e01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision tree\n",
        "We need to pass in the parameters for the maximum depth and features."
      ],
      "metadata": {
        "id": "YRCqtXOLrMYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_params = {\n",
        "    \"max_depth\": [3, 5, 8],\n",
        "    \"max_features\": [3, 5, 8]\n",
        "}\n",
        "\n",
        "dt_gs = GridSearchCV(\n",
        "    DecisionTree(random_state=RANDOM_STATE),\n",
        "    dt_params,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "dt_gs.fit(\n",
        "    features_train,\n",
        "    target_train\n",
        ")\n",
        "\n",
        "add_result(\"Decision Tree\", dt_gs.best_params_, dt_gs.best_score_)"
      ],
      "metadata": {
        "id": "zqPmH-bo9iPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random forest\n",
        "We need to pass in parameters for the maximum depth and features along with the number of estimators to be used.\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Hint\n",
        "</summary>\n",
        "Look at the imports in the beginning. See how random forest model is called.\n",
        "<details>\n",
        "<summary>\n",
        "Hint 2\n",
        "</summary>\n",
        "\n",
        "<pre>\n",
        "rf_gs = GridSearchCV(\n",
        "    RandomForest(random_state=RANDOM_STATE),\n",
        "    rf_params,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "</pre>\n",
        "</details>\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "rThADV-arRQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_params = {\n",
        "    \"max_depth\": [3, 5, 8],\n",
        "    \"max_features\": [3, 5, 8],\n",
        "    \"n_estimators\": [50, 100, 150, 200]\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "Task 5. Write the correct model into GridSearch, don't forget about the random state :)\n",
        "\"\"\"\n",
        "\n",
        "rf_gs = GridSearchCV(\n",
        "    # your code here,\n",
        "    rf_params,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "rf_gs.fit(\n",
        "    features_train,\n",
        "    target_train\n",
        ")\n",
        "\n",
        "add_result(\"Random Forest\", rf_gs.best_params_, rf_gs.best_score_)"
      ],
      "metadata": {
        "id": "aKBMyU3vD8Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting\n",
        "We need to pass in the learning rate, number of estimators and the maximum depth of the tree.\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Hint\n",
        "</summary>\n",
        "Repeat the same thing we did previously\n",
        "<details>\n",
        "<summary>\n",
        "Hint 2\n",
        "</summary>\n",
        "\n",
        "<pre>\n",
        "gb_gs = GridSearchCV(\n",
        "    LGBMRegressor(),\n",
        "    gb_params,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "gb_gs.fit(\n",
        "    features_train,\n",
        "    target_train\n",
        ")\n",
        "</pre>\n",
        "</details>\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "3tii_1GOrXo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Task 6. Define the GridSearch and fit it for gradient boosting yourself. The search params for grid search are given\n",
        "\"\"\"\n",
        "\n",
        "gb_params = {\n",
        "    \"learning_rate\": [0.1, 0.01, 0.001],\n",
        "    \"n_estimators\": [50, 100, 150, 200],\n",
        "    \"max_depth\": [3, 5, 8]\n",
        "}\n",
        "\n",
        "# write code here\n",
        "\n",
        "add_result(\"Gradient Boosting\", gb_gs.best_params_, gb_gs.best_score_)"
      ],
      "metadata": {
        "id": "DY2xVP3zF6LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations! You (may) have created your first set of ML models. Unfortunately, not all models are created equal and some will do better than others on a particular task."
      ],
      "metadata": {
        "id": "3UpcboaX8cOJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Selection\n",
        "\n",
        "Let's compare the trained models and select the best one\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Hint\n",
        "</summary>\n",
        "The metric is MSE.\n",
        "<details>\n",
        "<summary>\n",
        "Hint 2\n",
        "</summary>\n",
        "\n",
        "<pre>\n",
        "results.sort_values(\n",
        "    by = \"MSE\",\n",
        "    ascending=True\n",
        ")\n",
        "</pre>\n",
        "</details>\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "MmiiRb8aqH-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Task 7. Display the results table sorted by the metric \n",
        "\"\"\"\n",
        "\n",
        "results.sort_values(\n",
        "    by = # write code here, \n",
        "    ascending=True\n",
        ")"
      ],
      "metadata": {
        "id": "2FAy1ULPLUd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the __________ model has the lowest MSE on cross validation. Therefore, we will proceed with this model."
      ],
      "metadata": {
        "id": "5EhI0OmzqiAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing\n",
        "Now that we have our model, we can test it using the testing data that we set aside earlier.\n",
        "\n",
        "First, let's recreate the model.\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Hint\n",
        "</summary>\n",
        "You can get the best model from the grid search by doing <pre>gs.best_model_</pre> But the best model (technicaly) should be the linear regression, so just define it.\n",
        "<details>\n",
        "<summary>\n",
        "Hint 2\n",
        "</summary>\n",
        "Ideally it would be \n",
        "<pre>best_model = gs.best_model_</pre>\n",
        "\n",
        "but we didn't do grid search for linear regression, so just do\n",
        "<pre>best_model = LinearRegression()</pre>\n",
        "</details>\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "wr4OfiagsZlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Task 8. Select the best model\n",
        "\"\"\"\n",
        "\n",
        "best_model = # write code here\n",
        "\n",
        "best_model.fit(\n",
        "    features_train,\n",
        "    target_train\n",
        ")"
      ],
      "metadata": {
        "id": "IDhpUoFwqNiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can begin testing.\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Hint\n",
        "</summary>\n",
        "Put the features of the test set.\n",
        "<details>\n",
        "<summary>\n",
        "Hint 2\n",
        "</summary>\n",
        "<pre>features_test</pre>\n",
        "</details>\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "pIelE-zS-gFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Task 9. Make predictions on the test features\n",
        "\"\"\"\n",
        "\n",
        "preds_test = best_model.predict(\n",
        "    # write code here\n",
        ")"
      ],
      "metadata": {
        "id": "X57XgeDZsdnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to determine the performance of the model on the test set, we can observe the mean squared error."
      ],
      "metadata": {
        "id": "DRPYf2bI9mN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse(target_test, preds_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWOmST0WsyI-",
        "outputId": "a06de679-568e-49d8-a93d-30854515d64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8480809885823961"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check whether the model did actually learn anything, we will compare it to a dummy model which returns a constant prediction (median of the target value)."
      ],
      "metadata": {
        "id": "omPLBLdFwT0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_model = DummyRegressor(\n",
        "    strategy=\"median\"\n",
        ")\n",
        "\n",
        "dummy_model.fit(\n",
        "    features_train,\n",
        "    target_train\n",
        ")\n",
        "\n",
        "dummy_preds_test = dummy_model.predict(\n",
        "    features_test\n",
        ")\n",
        "\n",
        "mse(target_test, dummy_preds_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71-qBQRXwIfb",
        "outputId": "012e8f4e-5ed7-4230-e10e-3b90d8aed537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.6"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model preforms better than the dummy model (1.8 < 10.6) – sanity check passed! All good :)"
      ],
      "metadata": {
        "id": "_oDXoxUswhIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Bonus] Interpreting the model\n",
        "\n",
        "Let's find the most important features\n",
        "\n",
        "<details>\n",
        "<summary>\n",
        "Hint\n",
        "</summary>\n",
        "\n",
        "Try looking at the `feature_importances_` attribute of the best model\n",
        "- [Example for forests](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html)\n",
        "- For a linear model you can look at `coef_` attribute instead of `feature_importances_` ([docs](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html))\n",
        "\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "ur86HSLnvWOE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z6JFsLsau9Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "_Write a conclusion: what models have you tried? what model preformed the best? what are its parameters? what is the best score did you get?_\n"
      ],
      "metadata": {
        "id": "mcDbeXA7uj0T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PRjcWlwhyyPV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}